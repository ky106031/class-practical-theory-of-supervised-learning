{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b02fc123",
   "metadata": {},
   "source": [
    "# 様々な教師あり学習手法の実装と評価"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cb597e",
   "metadata": {},
   "source": [
    "## データセットの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4b5321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification, make_blobs, make_moons, make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce939113",
   "metadata": {},
   "source": [
    "### 線形分離可能なデータ（2クラス）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d3bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_blobs関数を使います。\n",
    "X, y = make_blobs(\n",
    "    n_samples=500, # サンプル数\n",
    "    n_features=2, # 特徴量の数。今回は2変数で。\n",
    "    centers=[[0, 0], [1, 1]], # 各クラスの中心。この値を中心にガウス分布でデータを生成します。\n",
    "    cluster_std=[0.4, 0.4], # 各クラスの標準偏差。これが大きいと、データがばらけます。\n",
    "    random_state=100, # 再現性のための乱数の種。好きな数字をどうぞ。\n",
    ")\n",
    "# データをランダムに訓練用とテスト用に分けます。\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1384a586",
   "metadata": {},
   "source": [
    "## データを散布図で可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87978ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=\"viridis\", edgecolor=\"k\", marker=\"o\")\n",
    "# ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=\"coolwarm\", marker=\"x\") # テストデータも同時に表示したい場合はこの行をコメントアウトしてください。\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf90172",
   "metadata": {},
   "source": [
    "## モデルの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5790aba1",
   "metadata": {},
   "source": [
    "### サポートベクトルマシン(線形カーネル)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db14554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel=\"linear\", C=1.0)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b54854",
   "metadata": {},
   "source": [
    "## 精度評価と識別境界の表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b333d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# テストデータで予測を行います。\n",
    "y_pred = model.predict(X_test)\n",
    "# 精度を計算します。\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"精度: {accuracy:.2f}\")\n",
    "\n",
    "# 混同行列を計算します。\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.matshow(cm, cmap=\"Blues\")  # 混同行列をヒートマップで表示\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(x=j, y=i, s=cm[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50699b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 識別境界を描画します。\n",
    "# 描画範囲を決める。訓練データの最小値と最大値を使います。\n",
    "xmin, xmax = X_train[:, 0].min(), X_train[:, 0].max() \n",
    "ymin, ymax = X_train[:, 1].min(), X_train[:, 1].max() \n",
    "\n",
    "# xmin～xmax, ymin～ymaxの範囲で200x200のメッシュグリッドを作成します。\n",
    "xx, yy = np.meshgrid(np.linspace(xmin, xmax, 200), np.linspace(ymin, ymax, 200))\n",
    "\n",
    "# メッシュグリッドの各点(200*200=40000サンプル)で予測を行います。\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "# 予測結果を元の形(200x200)に戻します。\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# 識別境界を描画します。\n",
    "plt.contourf(xx, yy, Z, alpha=0.8) # 200x200のメッシュグリッドを描画\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=\"viridis\", edgecolor=\"k\", marker=\"o\") # 訓練データを描画。不要ならコメントアウトしてください。\n",
    "# plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=\"coolwarm\", marker=\"x\") # テストデータも同時に表示したい場合はこの行をコメントアウトしてください。\n",
    "plt.contour(xx, yy, Z, levels=[0], colors=\"red\", linewidths=1) # 識別境界を赤色で描画\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.ylim(ymin, ymax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c932a1df",
   "metadata": {},
   "source": [
    "# 演習\n",
    "\n",
    "いろいろなデータ、いろいろなモデルを用いて境界がどのように変わるのか試してみてください。\n",
    "\n",
    "以下に、使えそうなデータの作り方、モデルの作り方を示します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04a7086",
   "metadata": {},
   "source": [
    "## データセットの準備（その２）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1377bc9b",
   "metadata": {},
   "source": [
    "### 線形分離不可能なデータ（円状に分布）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25406e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_circles(\n",
    "    n_samples=500, # サンプル数\n",
    "    noise=0.2, # ノイズの大きさ。これが大きいと、データがばらけます。\n",
    "    factor=0.5, # 内側の円と外側の円の距離。これが大きいと、データがばらけます。\n",
    "    random_state=100, # 再現性のための乱数の種。好きな数字をどうぞ。\n",
    ")\n",
    "# データをランダムに訓練用とテスト用に分けます。\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab99c131",
   "metadata": {},
   "source": [
    "### 線形分離不可能なデータ（三日月状に分布）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0028e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(\n",
    "    n_samples=500, # サンプル数\n",
    "    noise=0.2, # ノイズの大きさ。これが大きいと、データがばらけます。\n",
    "    random_state=100, # 再現性のための乱数の種。好きな数字をどうぞ。\n",
    ")\n",
    "# データをランダムに訓練用とテスト用に分けます。\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a683f62",
   "metadata": {},
   "source": [
    "### 不均衡データの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e37af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "# X_train, y_trainのクラス0のサンプル数を減らします。\n",
    "percent = 0.1 # クラス0のサンプル数を10%にします。\n",
    "\n",
    "class0_idx = np.where(y_train == 0)[0] # クラス0データが何番目にあるかを取得\n",
    "class1_idx = np.where(y_train == 1)[0] # クラス1データが何番目にあるかを取得\n",
    "\n",
    "n_class0 = int(len(class0_idx) * percent) # クラス0のサンプル数を10%にします。\n",
    "selected0_idx = np.random.choice(class0_idx, size=n_class0, replace=False) # 10%のサンプルをランダムに選択\n",
    "\n",
    "new_idx = np.concatenate([selected0_idx, class1_idx]) # 減らしたクラス0のサンプルとクラス1のサンプルを結合\n",
    "X_train = X_train[new_idx] # 訓練データを更新\n",
    "y_train = y_train[new_idx] # 訓練データを更新\n",
    "\n",
    "# シャッフルした方がよさそう\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "print(f\"クラス0の訓練サンプル数: {len(np.where(y_train == 0)[0])}\")\n",
    "print(f\"クラス1の訓練サンプル数: {len(np.where(y_train == 1)[0])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d112bb",
   "metadata": {},
   "source": [
    "## モデルの学習（その２）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b695789e",
   "metadata": {},
   "source": [
    "### サポートベクトルマシン（ガウスカーネル）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25447918",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel=\"rbf\", C=1.0)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a05e41",
   "metadata": {},
   "source": [
    "### 決定木"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973cf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier  # 決定木分類器\n",
    "model = DecisionTreeClassifier(max_depth=3)  # max_depthは木の深さ\n",
    "# model = DecisionTreeClassifier(criterion=\"gini\", ccp_alpha=0.0) # αを指定して枝刈りする場合\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e65c02",
   "metadata": {},
   "source": [
    "### ランダムフォレスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da00a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier  # ランダムフォレスト分類器\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=3)  # n_estimatorsは木の本数\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007e4acf",
   "metadata": {},
   "source": [
    "### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69e1017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,  # 木の数\n",
    "    max_depth=3,  # 木の深さ\n",
    "    learning_rate=0.1,  # 学習率\n",
    "    random_state=100,  # 再現性のための乱数シード\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2febfab7",
   "metadata": {},
   "source": [
    "### ロジスティック回帰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331424ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ロジスティック回帰\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(\n",
    "    penalty=\"l2\",  # 正則化の種類。l1はLasso、l2はRidge\n",
    "    C=1.0,  # 正則化の強さ。小さいほど正則化が強くなる\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8ed22c",
   "metadata": {},
   "source": [
    "### ニューラルネット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5d59db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3層のニューラルネット。KerasとかPyTorchとか使わずにやってみます。\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 50), \n",
    "    solver=\"sgd\",  # Optimizer。今回は確率的勾配降下法を指定。他には\"adam\"や\"lbfgs\"など\n",
    "    learning_rate_init=0.001,  # 学習率\n",
    "    max_iter=10000,  # 最大反復回数\n",
    ") # 他にもたくさんパラメータがあります。詳しくは、https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b6ba6a",
   "metadata": {},
   "source": [
    "### k-近傍法\n",
    "k-近傍法は、推論時に入力データに最も近いk個の訓練データを探し、そのk個のデータのラベルの多数決をとる手法です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be2884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=5)  # k近傍法。k=5\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fa3410",
   "metadata": {},
   "source": [
    "## SMOTEによるOverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad10cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto') # 自動でクラスのサンプル数を揃える\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train) # 訓練データをリサンプリング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2811f19a",
   "metadata": {},
   "source": [
    "## [おまけ] 計算時間を測りたい場合\n",
    "\n",
    "いくつか方法がありますが、perf_counterを使う方法を紹介します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01529881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 高精度な計測\n",
    "start = time.perf_counter() # ストップウォッチ開始\n",
    "\n",
    "# ここに計測したい処理を書く。サンプルとして円周率を計算する処理を入れています。\n",
    "pi = 0\n",
    "for i in range(1000000): # なんか時間かかりそうな処理\n",
    "    pi += (4 * ((-1) ** i)) / (2 * i + 1) # ライプニッツの公式。詳しくはchatGPTに聞いてください。\n",
    "\n",
    "end = time.perf_counter() # ストップウォッチ終了\n",
    "print(f\"処理時間: {end - start}秒\")\n",
    "print(f\"円周率: {pi:.10f}\") # 小数点以下10桁まで表示\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
